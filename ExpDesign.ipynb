{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Expirement Design for Data Science\n",
    "## Group 26\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from os import listdir\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# run in normal python shell once:\n",
    "#>>> import nltk\n",
    "#>>> nltk.download()\n",
    "# and download all packages (easiest)"
   ]
  },
  {
   "source": [
    "### Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 20 newsgroups dataset\n",
    "\n",
    "newsgroups_train = datasets.fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = datasets.fetch_20newsgroups(subset='test')\n",
    "\n",
    "# Subjectivity dataset\n",
    "subjective_sentences_file = './data/Movie_Review/Subjectivity/plot.tok.gt9.5000'\n",
    "objective_sentences_file = './data/Movie_Review/Subjectivity/quote.tok.gt9.5000'\n",
    "\n",
    "subjective_sentences = pd.read_csv(subjective_sentences_file, header=None, sep='|', encoding='latin-1', names=['text'])\n",
    "objective_sentences = pd.read_csv(objective_sentences_file, header=None, sep='|', encoding='latin-1', names=['text'])\n",
    "\n",
    "subjective_sentences['subjective'] = 1\n",
    "objective_sentences['subjective'] = 0\n",
    "\n",
    "subjectivity_complete = pd.concat([subjective_sentences, objective_sentences])\n",
    "\n",
    "# Sentence polarity dataset\n",
    "\n",
    "neg_directory = './data/Movie_Review/Sentence_Polarity/neg/'\n",
    "pos_directory = './data/Movie_Review/Sentence_Polarity/pos/'\n",
    "\n",
    "neg_files = os.listdir(neg_directory)\n",
    "pos_files = os.listdir(pos_directory)\n",
    "\n",
    "neg_sentences = []\n",
    "pos_sentences = []\n",
    "\n",
    "for file in neg_files:\n",
    "    with open(neg_directory + file, 'r') as f:\n",
    "        neg_sentences.append(f.read())\n",
    "        \n",
    "for file in pos_files:\n",
    "    with open(pos_directory + file, 'r') as f:\n",
    "        pos_sentences.append(f.read())\n",
    "\n",
    "neg_sentences = pd.DataFrame(neg_sentences, columns=['text'])\n",
    "pos_sentences = pd.DataFrame(pos_sentences, columns=['text'])\n",
    "\n",
    "neg_sentences['positive'] = 0\n",
    "pos_sentences['positive'] = 1\n",
    "\n",
    "polarity_complete = pd.concat([neg_sentences, pos_sentences])\n",
    "\n",
    "# TREC 45\n",
    "\n",
    "### TODO\n",
    "\n",
    "# Debug\n",
    "\n",
    "#print(newsgroups_train)\n",
    "#print(subjectivity_complete.head())\n",
    "#print(polarity_complete.head())"
   ]
  },
  {
   "source": [
    "### Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def tokenize_text (text):\n",
    "    tokens = []\n",
    "    for sentences in nltk.sent_tokenize(text):\n",
    "        for token in nltk.word_tokenize(text):\n",
    "            if token not in stopwords.words('english'):\n",
    "                tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "# Tokenize Subjectivity\n",
    "subjectivity_tokenized = [tokenize_text(text) for text in subjectivity_complete['text']]   # Tokenized data\n",
    "subjectivity_complete['tokens'] = subjectivity_tokenized\n",
    "\n",
    "# Tokenize Polarity\n",
    "polarity_tokenized = [tokenize_text(text) for text in polarity_complete['text']]   # Tokenized data\n",
    "polarity_complete['tokens'] = polarity_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                text  subjective  \\\n0  the movie begins in the past where a young boy...           1   \n1  emerging from the human psyche and showing cha...           1   \n2  spurning her mother's insistence that she get ...           1   \n3  amitabh can't believe the board of directors a...           1   \n4  she , among others excentricities , talks to a...           1   \n\n                                              tokens  \n0  [movie, begins, past, young, boy, named, sam, ...  \n1  [emerging, human, psyche, showing, characteris...  \n2  [spurning, mother, 's, insistence, get, life, ...  \n3  [amitabh, ca, n't, believe, board, directors, ...  \n4  [,, among, others, excentricities, ,, talks, s...  \n                                                text  positive  \\\n0  plot : two teen couples go to a church party ,...         0   \n1  the happy bastard's quick movie review \\ndamn ...         0   \n2  it is movies like these that make a jaded movi...         0   \n3   \" quest for camelot \" is warner bros . ' firs...         0   \n4  synopsis : a mentally unstable man undergoing ...         0   \n\n                                              tokens  \n0  [plot, :, two, teen, couples, go, church, part...  \n1  [happy, bastard, 's, quick, movie, review, dam...  \n2  [movies, like, make, jaded, movie, viewer, tha...  \n3  [``, quest, camelot, ``, warner, bros, ., ', f...  \n4  [synopsis, :, mentally, unstable, man, undergo...  \n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "print(subjectivity_complete.head())\n",
    "print(polarity_complete.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(subjectivity_complete, open('./data/variable_storage/subjectivity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}