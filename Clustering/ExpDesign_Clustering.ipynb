{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirement Design for Data Science - Clustering\n",
    "## Group 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# download all packages (easiest) with:\n",
    "#nltk.download()\n",
    "\n",
    "import initialize\n",
    "import pip\n",
    "\n",
    "# if you use the notebook for the first time, also run: \n",
    "#pip.main(['install', 'spherecluster'])\n",
    "\n",
    "# in case you get the following error message from the installation of spherecluster: \n",
    "# ImportError: cannot import name '_k_means' from 'sklearn.cluster' \n",
    "# Open the file spherical_kmeans.py (path specified in the error message) and replace in line 16 '_k_means' with 'KMeans'\n",
    "\n",
    "\n",
    "# modified data file from the original publication (https://link.springer.com/chapter/10.1007%2F978-3-030-45442-5_7#Bib1):\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Checking the data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(news_train, news_test) = initialize.get_20_newsgroups_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:\n",
      "\n",
      "Train set: 11314\n",
      "Test set: 7532\n",
      "Total: 18846\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\\n\")\n",
    "print(\"Train set: {}\".format(len(news_train.filenames)))\n",
    "print(\"Test set: {}\".format(len(news_test.filenames)))\n",
    "print(\"Total: {}\".format(len(news_train.filenames) + len(news_test.filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels to file for later need.\n",
    "np.save('news_test_labels', news_test.target)\n",
    "np.save('news_train_labels', news_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Tokenize the data sets\n",
    "This can take quite some time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization of train set OK; original data removed.\n",
      "Tokenization of test set OK; original data removed.\n"
     ]
    }
   ],
   "source": [
    "tok_twenty_train = [tokenize_text(sent) for sent in news_train.data]  # Tokenized train data\n",
    "tok_twenty_test = [tokenize_text(sent) for sent in news_test.data]    # Tokenized test data\n",
    "\n",
    "# If everything works, delete the original ROB04_data to save RAM.\n",
    "if (len(tok_twenty_train) == len(news_train.data)):\n",
    "    print(\"Tokenization of train set OK; original data removed.\")\n",
    "    del news_train\n",
    "    \n",
    "if (len(tok_twenty_test) == len(news_test.data)):\n",
    "    print(\"Tokenization of test set OK; original data removed.\")\n",
    "    del news_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenized datasets to a file (tokenization takes time).\n",
    "with open(\"tok_twenty_train.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tok_twenty_train)\n",
    "    \n",
    "with open(\"tok_twenty_test.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tok_twenty_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tokenized train and test sets, generate also a total file:\n",
    "tok_twenty_tot =[]   # new code lines\n",
    "\n",
    "tok_twenty_train = []  # List to store train set\n",
    "tok_twenty_test = []   # List to store test set\n",
    "\n",
    "with open('tok_twenty_train.csv') as csvfile:\n",
    "    read = csv.reader(csvfile, delimiter = ',')\n",
    "    for row in read:\n",
    "        tok_twenty_train.append(row)\n",
    "        tok_twenty_tot.append(row) # new code lines\n",
    "        \n",
    "with open('tok_twenty_test.csv') as csvfile:\n",
    "    read = csv.reader(csvfile, delimiter = ',')\n",
    "    for row in read:\n",
    "        tok_twenty_test.append(row)\n",
    "        tok_twenty_tot.append(row) # new code lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation of the different models also the labels of the total dataset has to be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new code lines: \n",
    "\n",
    "# load the labels from training and test set:\n",
    "arr1 = np.load('news_train_labels.npy')\n",
    "arr2 = np.load('news_test_labels.npy')\n",
    "\n",
    "# combine the labels: \n",
    "arr3 = np.append(arr1 , arr2)\n",
    "\n",
    "# save the labels for later usage:\n",
    "np.save('twenty_labels_tot', arr3)\n",
    "twenty_labels_tot = np.load('twenty_labels_tot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 11314\n",
      "Test set: 7532\n",
      "Total: 18846\n"
     ]
    }
   ],
   "source": [
    "# check for correct length:\n",
    "print(\"Train set: {}\".format(len(arr1)))\n",
    "print(\"Test set: {}\".format(len(arr2)))\n",
    "print(\"Total: {}\".format(len(arr1) + len(arr2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 50     # Number of topics for LSI and LDA.\n",
    "               # Vector dimension for cBow and PV.\n",
    "mix_comp = 15  # Mixture components.\n",
    "K = 20         # Number of clusters.\n",
    "n_feat = 5000  # Number of features.\n",
    "\n",
    "n_top_high = 100  # For computations with 100-dim. feat. vectors.\n",
    "n_top_low = 20    # For computations with 20-dim. feat. vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat clustering 10 times (running the code takes some time).\n",
    "\n",
    "The code had to be changed in line 24, as no label argument was defined within the evaluate_cluster() function. \n",
    "Unfortunately for this part of code there are no result files from the original available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 62\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.575\n",
      "NMI: 3.725\n",
      "Processing i = 1.\n",
      "Iteration number: 72\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.313\n",
      "NMI: 3.242\n",
      "Processing i = 2.\n",
      "Iteration number: 80\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.551\n",
      "NMI: 3.720\n",
      "Processing i = 3.\n",
      "Iteration number: 86\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.571\n",
      "NMI: 3.767\n",
      "Processing i = 4.\n",
      "Iteration number: 67\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.564\n",
      "NMI: 3.743\n",
      "Processing i = 5.\n",
      "Iteration number: 61\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.317\n",
      "NMI: 3.319\n",
      "Processing i = 6.\n",
      "Iteration number: 86\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.617\n",
      "NMI: 3.777\n",
      "Processing i = 7.\n",
      "Iteration number: 62\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.365\n",
      "NMI: 3.425\n",
      "Processing i = 8.\n",
      "Iteration number: 86\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.317\n",
      "NMI: 3.295\n",
      "Processing i = 9.\n",
      "Iteration number: 88\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.566\n",
      "NMI: 3.698\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 18\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.117\n",
      "Processing i = 1.\n",
      "Iteration number: 7\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.056\n",
      "Processing i = 2.\n",
      "Iteration number: 20\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.109\n",
      "Processing i = 3.\n",
      "Iteration number: 7\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.094\n",
      "Processing i = 4.\n",
      "Iteration number: 16\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.083\n",
      "Processing i = 5.\n",
      "Iteration number: 6\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.018\n",
      "NMI: 0.988\n",
      "Processing i = 6.\n",
      "Iteration number: 7\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.042\n",
      "Processing i = 7.\n",
      "Iteration number: 6\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.052\n",
      "Processing i = 8.\n",
      "Iteration number: 9\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.052\n",
      "Processing i = 9.\n",
      "Iteration number: 9\n",
      "Clustering performance for TF-IDF:\n",
      "ARI: 0.011\n",
      "NMI: 1.087\n"
     ]
    }
   ],
   "source": [
    "### Try several clustering runs and store results.\n",
    "\n",
    "# Convert a collection of text documents into a matrix of token counts.\n",
    "count_vectorizer_TFIDF = CountVectorizer(tokenizer=identity_tokenizer, \n",
    "                                         lowercase=False, max_features=n_feat)\n",
    "\n",
    "# Matrix of shape len(data) x #words.\n",
    "twenty_features_TFIDF = count_vectorizer_TFIDF.fit_transform(tok_twenty_tot)\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_TFIDF = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_TFIDF.fit(twenty_features_TFIDF)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_TFIDF, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_TFIDF.n_iter_))\n",
    "        print(\"Clustering performance for TF-IDF:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_TFIDF = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                        columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_TFIDF.round(3).to_csv('results/TFIDF_clust.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI_random</th>\n",
       "      <th>NMI_random</th>\n",
       "      <th>ARI_kmeans</th>\n",
       "      <th>NMI_kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575</td>\n",
       "      <td>3.725</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.313</td>\n",
       "      <td>3.242</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.551</td>\n",
       "      <td>3.720</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571</td>\n",
       "      <td>3.767</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.564</td>\n",
       "      <td>3.743</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.317</td>\n",
       "      <td>3.319</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.617</td>\n",
       "      <td>3.777</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.365</td>\n",
       "      <td>3.425</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.317</td>\n",
       "      <td>3.295</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.566</td>\n",
       "      <td>3.698</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARI_random  NMI_random  ARI_kmeans  NMI_kmeans\n",
       "0       0.575       3.725       0.011       1.117\n",
       "1       0.313       3.242       0.011       1.056\n",
       "2       0.551       3.720       0.011       1.109\n",
       "3       0.571       3.767       0.011       1.094\n",
       "4       0.564       3.743       0.011       1.083\n",
       "5       0.317       3.319       0.018       0.988\n",
       "6       0.617       3.777       0.011       1.042\n",
       "7       0.365       3.425       0.011       1.052\n",
       "8       0.317       3.295       0.011       1.052\n",
       "9       0.566       3.698       0.011       1.087"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dictionary and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gensim dictionary and corpus.\n",
    "dct = corpora.Dictionary(tok_twenty_tot)\n",
    "# Gensim uses bag of wards to represent in this form.\n",
    "corpus_twenty = [dct.doc2bow(sent) for sent in tok_twenty_tot]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 63\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.697\n",
      "NMI: 3.854\n",
      "Processing i = 1.\n",
      "Iteration number: 81\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.608\n",
      "NMI: 3.802\n",
      "Processing i = 2.\n",
      "Iteration number: 64\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.716\n",
      "NMI: 3.916\n",
      "Processing i = 3.\n",
      "Iteration number: 69\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.544\n",
      "NMI: 3.731\n",
      "Processing i = 4.\n",
      "Iteration number: 78\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.610\n",
      "NMI: 3.806\n",
      "Processing i = 5.\n",
      "Iteration number: 78\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.311\n",
      "NMI: 3.291\n",
      "Processing i = 6.\n",
      "Iteration number: 73\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.721\n",
      "NMI: 4.080\n",
      "Processing i = 7.\n",
      "Iteration number: 60\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.591\n",
      "NMI: 3.847\n",
      "Processing i = 8.\n",
      "Iteration number: 64\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.589\n",
      "NMI: 3.840\n",
      "Processing i = 9.\n",
      "Iteration number: 75\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.617\n",
      "NMI: 3.753\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 11\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.018\n",
      "NMI: 0.956\n",
      "Processing i = 1.\n",
      "Iteration number: 8\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.079\n",
      "Processing i = 2.\n",
      "Iteration number: 18\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.141\n",
      "Processing i = 3.\n",
      "Iteration number: 22\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.084\n",
      "Processing i = 4.\n",
      "Iteration number: 28\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.028\n",
      "NMI: 1.537\n",
      "Processing i = 5.\n",
      "Iteration number: 16\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.095\n",
      "Processing i = 6.\n",
      "Iteration number: 19\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.110\n",
      "Processing i = 7.\n",
      "Iteration number: 8\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.019\n",
      "Processing i = 8.\n",
      "Iteration number: 6\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.011\n",
      "NMI: 1.028\n",
      "Processing i = 9.\n",
      "Iteration number: 8\n",
      "Clustering performance for LSI:\n",
      "ARI: 0.010\n",
      "NMI: 1.051\n"
     ]
    }
   ],
   "source": [
    "# Run LSI model to get topic modelling.\n",
    "lsi_model_twenty = LsiModel(corpus=corpus_twenty, num_topics=n_top_high, id2word=dct)\n",
    "\n",
    "# Converting topics to feature vectors.\n",
    "# The probability distribution of the topics for \n",
    "# a specific review will be our feature vector.\n",
    "\n",
    "feat_vecs_twenty = matutils.corpus2dense(lsi_model_twenty[corpus_twenty], num_terms=n_top_high).T.tolist()\n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_LSI = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_LSI.fit(feat_vecs_twenty)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_LSI, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_LSI.n_iter_))\n",
    "        print(\"Clustering performance for LSI:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_LSI = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                      columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_LSI.round(3).to_csv('results/LSI_clust_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI_random</th>\n",
       "      <th>NMI_random</th>\n",
       "      <th>ARI_kmeans</th>\n",
       "      <th>NMI_kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.697289</td>\n",
       "      <td>3.854219</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.956284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608305</td>\n",
       "      <td>3.801824</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>1.078630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.715680</td>\n",
       "      <td>3.915953</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>1.141271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.543538</td>\n",
       "      <td>3.731247</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>1.083788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610418</td>\n",
       "      <td>3.806324</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>1.536651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.310731</td>\n",
       "      <td>3.291402</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>1.095184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.721423</td>\n",
       "      <td>4.079949</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>1.110189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.591261</td>\n",
       "      <td>3.847428</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>1.019375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.589166</td>\n",
       "      <td>3.840464</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>1.027931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616700</td>\n",
       "      <td>3.752970</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>1.051045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARI_random  NMI_random  ARI_kmeans  NMI_kmeans\n",
       "0    0.697289    3.854219    0.018136    0.956284\n",
       "1    0.608305    3.801824    0.010717    1.078630\n",
       "2    0.715680    3.915953    0.010826    1.141271\n",
       "3    0.543538    3.731247    0.010673    1.083788\n",
       "4    0.610418    3.806324    0.028034    1.536651\n",
       "5    0.310731    3.291402    0.010934    1.095184\n",
       "6    0.721423    4.079949    0.010556    1.110189\n",
       "7    0.591261    3.847428    0.010708    1.019375\n",
       "8    0.589166    3.840464    0.010802    1.027931\n",
       "9    0.616700    3.752970    0.010474    1.051045"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_twenty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7940206f2842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run LDA model to get topic modelling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m lda_model_twenty = LdaMulticore(corpus=corpus_twenty, num_topics=n_top_high, id2word=dct,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 passes=60, workers=6)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus_twenty' is not defined"
     ]
    }
   ],
   "source": [
    "# Run LDA model to get topic modelling.\n",
    "lda_model_twenty = LdaMulticore(corpus=corpus_twenty, num_topics=n_top_high, id2word=dct,\n",
    "                                passes=60, workers=6)\n",
    "\n",
    "# Save model\n",
    "# lda_model_twenty.save(\"models/LDA/LDA_clustering.model\")\n",
    "\n",
    "# Converting topics to feature vectors\n",
    "# The probability distribution of the topics for \n",
    "# a specific review will be our feature vector.\n",
    "\n",
    "feat_vecs_twenty = []\n",
    "\n",
    "for i in range(len(corpus_twenty)):\n",
    "    top_topics = lda_model_twenty.get_document_topics(corpus_twenty[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(n_top_high)]\n",
    "    feat_vecs_twenty.append(topic_vec)\n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_LDA = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_LDA.fit(feat_vecs_twenty)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_LDA, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_LDA.n_iter_))\n",
    "        print(\"Clustering performance for LDA:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_LDA = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                      columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_LDA.round(3).to_csv('results/LDA_clust_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. cBow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 91\n",
      "Clustering performance for cBow:\n",
      "ARI: 22.426\n",
      "NMI: 41.356\n",
      "Processing i = 1.\n",
      "Iteration number: 80\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.587\n",
      "NMI: 43.584\n",
      "Processing i = 2.\n",
      "Iteration number: 62\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.608\n",
      "NMI: 43.677\n",
      "Processing i = 3.\n",
      "Iteration number: 49\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.707\n",
      "NMI: 43.640\n",
      "Processing i = 4.\n",
      "Iteration number: 66\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.570\n",
      "NMI: 43.698\n",
      "Processing i = 5.\n",
      "Iteration number: 88\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.540\n",
      "NMI: 43.626\n",
      "Processing i = 6.\n",
      "Iteration number: 200\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.658\n",
      "NMI: 43.624\n",
      "Processing i = 7.\n",
      "Iteration number: 132\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.530\n",
      "NMI: 43.580\n",
      "Processing i = 8.\n",
      "Iteration number: 115\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.631\n",
      "NMI: 43.565\n",
      "Processing i = 9.\n",
      "Iteration number: 70\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.722\n",
      "NMI: 43.633\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 76\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.072\n",
      "NMI: 42.790\n",
      "Processing i = 1.\n",
      "Iteration number: 56\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.690\n",
      "NMI: 43.661\n",
      "Processing i = 2.\n",
      "Iteration number: 53\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.660\n",
      "NMI: 43.625\n",
      "Processing i = 3.\n",
      "Iteration number: 87\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.680\n",
      "NMI: 43.636\n",
      "Processing i = 4.\n",
      "Iteration number: 108\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.333\n",
      "NMI: 42.836\n",
      "Processing i = 5.\n",
      "Iteration number: 82\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.655\n",
      "NMI: 43.587\n",
      "Processing i = 6.\n",
      "Iteration number: 60\n",
      "Clustering performance for cBow:\n",
      "ARI: 23.109\n",
      "NMI: 41.044\n",
      "Processing i = 7.\n",
      "Iteration number: 114\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.651\n",
      "NMI: 43.594\n",
      "Processing i = 8.\n",
      "Iteration number: 53\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.585\n",
      "NMI: 43.561\n",
      "Processing i = 9.\n",
      "Iteration number: 55\n",
      "Clustering performance for cBow:\n",
      "ARI: 24.555\n",
      "NMI: 43.614\n"
     ]
    }
   ],
   "source": [
    "## Set-up w2v model.\n",
    "\n",
    "cores = 6      # Threads used for training\n",
    "\n",
    "# Initialize model.\n",
    "w2v_model_twenty = Word2Vec(size=n_top_high, window=5, min_count=1, workers=cores)\n",
    "\n",
    "# Build the vocabulary.\n",
    "w2v_model_twenty.build_vocab(tok_twenty_tot)\n",
    "\n",
    "# Train model.\n",
    "w2v_model_twenty.train(tok_twenty_tot, total_examples=w2v_model_twenty.corpus_count, epochs=60)\n",
    "\n",
    "# Save model.\n",
    "w2v_model_twenty.save(\"models/cBow/cBow_clustering_100topics.model\")\n",
    "\n",
    "w2v_model_twenty.init_sims(replace=True)\n",
    "\n",
    "# Getting feature vectors.\n",
    "twenty_w2v_aver = word_averaging_list(w2v_model_twenty.wv, tok_twenty_tot)\n",
    "\n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_cBow = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_cBow.fit(twenty_w2v_aver)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_cBow, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_cBow.n_iter_))\n",
    "        print(\"Clustering performance for cBow:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_cBow = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                       columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_cBow.round(3).to_csv('results/cBow_clust_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARI_random</th>\n",
       "      <th>NMI_random</th>\n",
       "      <th>ARI_kmeans</th>\n",
       "      <th>NMI_kmeans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.425526</td>\n",
       "      <td>41.355980</td>\n",
       "      <td>24.072269</td>\n",
       "      <td>42.789966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.587096</td>\n",
       "      <td>43.584043</td>\n",
       "      <td>24.689664</td>\n",
       "      <td>43.660655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.608407</td>\n",
       "      <td>43.677179</td>\n",
       "      <td>24.659662</td>\n",
       "      <td>43.625171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.706912</td>\n",
       "      <td>43.640046</td>\n",
       "      <td>24.680484</td>\n",
       "      <td>43.635702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.569937</td>\n",
       "      <td>43.698164</td>\n",
       "      <td>24.332699</td>\n",
       "      <td>42.836343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.539958</td>\n",
       "      <td>43.626031</td>\n",
       "      <td>24.654819</td>\n",
       "      <td>43.587220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.658053</td>\n",
       "      <td>43.624297</td>\n",
       "      <td>23.108998</td>\n",
       "      <td>41.044480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.530405</td>\n",
       "      <td>43.579807</td>\n",
       "      <td>24.651223</td>\n",
       "      <td>43.594205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.630834</td>\n",
       "      <td>43.564513</td>\n",
       "      <td>24.585026</td>\n",
       "      <td>43.560738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.721509</td>\n",
       "      <td>43.632774</td>\n",
       "      <td>24.555304</td>\n",
       "      <td>43.613814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARI_random  NMI_random  ARI_kmeans  NMI_kmeans\n",
       "0   22.425526   41.355980   24.072269   42.789966\n",
       "1   24.587096   43.584043   24.689664   43.660655\n",
       "2   24.608407   43.677179   24.659662   43.625171\n",
       "3   24.706912   43.640046   24.680484   43.635702\n",
       "4   24.569937   43.698164   24.332699   42.836343\n",
       "5   24.539958   43.626031   24.654819   43.587220\n",
       "6   24.658053   43.624297   23.108998   41.044480\n",
       "7   24.530405   43.579807   24.651223   43.594205\n",
       "8   24.630834   43.564513   24.585026   43.560738\n",
       "9   24.721509   43.632774   24.555304   43.613814"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cBow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. PV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,t6) vocabulary scanned and state initialized\n",
      "Doc2Vec(dm/m,d100,n5,w5,t6) vocabulary scanned and state initialized\n",
      "Training Doc2Vec(dbow,d100,n5,t6)\n",
      "Training Doc2Vec(dm/m,d100,n5,w5,t6)\n",
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 50\n",
      "Clustering performance for PV:\n",
      "ARI: 44.639\n",
      "NMI: 62.639\n",
      "Processing i = 1.\n",
      "Iteration number: 72\n",
      "Clustering performance for PV:\n",
      "ARI: 47.141\n",
      "NMI: 63.701\n",
      "Processing i = 2.\n",
      "Iteration number: 34\n",
      "Clustering performance for PV:\n",
      "ARI: 43.807\n",
      "NMI: 62.142\n",
      "Processing i = 3.\n",
      "Iteration number: 103\n",
      "Clustering performance for PV:\n",
      "ARI: 45.382\n",
      "NMI: 63.326\n",
      "Processing i = 4.\n",
      "Iteration number: 58\n",
      "Clustering performance for PV:\n",
      "ARI: 47.547\n",
      "NMI: 64.379\n",
      "Processing i = 5.\n",
      "Iteration number: 85\n",
      "Clustering performance for PV:\n",
      "ARI: 45.722\n",
      "NMI: 63.586\n",
      "Processing i = 6.\n",
      "Iteration number: 69\n",
      "Clustering performance for PV:\n",
      "ARI: 45.858\n",
      "NMI: 64.352\n",
      "Processing i = 7.\n",
      "Iteration number: 59\n",
      "Clustering performance for PV:\n",
      "ARI: 45.932\n",
      "NMI: 64.443\n",
      "Processing i = 8.\n",
      "Iteration number: 49\n",
      "Clustering performance for PV:\n",
      "ARI: 47.603\n",
      "NMI: 64.241\n",
      "Processing i = 9.\n",
      "Iteration number: 36\n",
      "Clustering performance for PV:\n",
      "ARI: 44.913\n",
      "NMI: 63.582\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 132\n",
      "Clustering performance for PV:\n",
      "ARI: 48.165\n",
      "NMI: 64.104\n",
      "Processing i = 1.\n",
      "Iteration number: 49\n",
      "Clustering performance for PV:\n",
      "ARI: 45.141\n",
      "NMI: 62.566\n",
      "Processing i = 2.\n",
      "Iteration number: 48\n",
      "Clustering performance for PV:\n",
      "ARI: 47.473\n",
      "NMI: 65.589\n",
      "Processing i = 3.\n",
      "Iteration number: 94\n",
      "Clustering performance for PV:\n",
      "ARI: 46.087\n",
      "NMI: 63.341\n",
      "Processing i = 4.\n",
      "Iteration number: 28\n",
      "Clustering performance for PV:\n",
      "ARI: 43.496\n",
      "NMI: 62.456\n",
      "Processing i = 5.\n",
      "Iteration number: 110\n",
      "Clustering performance for PV:\n",
      "ARI: 45.446\n",
      "NMI: 63.071\n",
      "Processing i = 6.\n",
      "Iteration number: 49\n",
      "Clustering performance for PV:\n",
      "ARI: 46.694\n",
      "NMI: 63.951\n",
      "Processing i = 7.\n",
      "Iteration number: 70\n",
      "Clustering performance for PV:\n",
      "ARI: 45.819\n",
      "NMI: 63.472\n",
      "Processing i = 8.\n",
      "Iteration number: 83\n",
      "Clustering performance for PV:\n",
      "ARI: 44.800\n",
      "NMI: 62.031\n",
      "Processing i = 9.\n",
      "Iteration number: 54\n",
      "Clustering performance for PV:\n",
      "ARI: 46.982\n",
      "NMI: 63.611\n",
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 133\n",
      "Clustering performance for PV:\n",
      "ARI: 10.964\n",
      "NMI: 37.006\n",
      "Processing i = 1.\n",
      "Iteration number: 52\n",
      "Clustering performance for PV:\n",
      "ARI: 8.563\n",
      "NMI: 38.486\n",
      "Processing i = 2.\n",
      "Iteration number: 57\n",
      "Clustering performance for PV:\n",
      "ARI: 11.108\n",
      "NMI: 38.507\n",
      "Processing i = 3.\n",
      "Iteration number: 56\n",
      "Clustering performance for PV:\n",
      "ARI: 8.245\n",
      "NMI: 36.770\n",
      "Processing i = 4.\n",
      "Iteration number: 60\n",
      "Clustering performance for PV:\n",
      "ARI: 11.020\n",
      "NMI: 38.593\n",
      "Processing i = 5.\n",
      "Iteration number: 111\n",
      "Clustering performance for PV:\n",
      "ARI: 7.307\n",
      "NMI: 36.773\n",
      "Processing i = 6.\n",
      "Iteration number: 46\n",
      "Clustering performance for PV:\n",
      "ARI: 8.004\n",
      "NMI: 37.494\n",
      "Processing i = 7.\n",
      "Iteration number: 34\n",
      "Clustering performance for PV:\n",
      "ARI: 10.975\n",
      "NMI: 37.049\n",
      "Processing i = 8.\n",
      "Iteration number: 51\n",
      "Clustering performance for PV:\n",
      "ARI: 8.894\n",
      "NMI: 38.785\n",
      "Processing i = 9.\n",
      "Iteration number: 103\n",
      "Clustering performance for PV:\n",
      "ARI: 8.736\n",
      "NMI: 39.878\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 38\n",
      "Clustering performance for PV:\n",
      "ARI: 6.709\n",
      "NMI: 31.957\n",
      "Processing i = 1.\n",
      "Iteration number: 47\n",
      "Clustering performance for PV:\n",
      "ARI: 7.461\n",
      "NMI: 34.381\n",
      "Processing i = 2.\n",
      "Iteration number: 34\n",
      "Clustering performance for PV:\n",
      "ARI: 8.954\n",
      "NMI: 33.147\n",
      "Processing i = 3.\n",
      "Iteration number: 38\n",
      "Clustering performance for PV:\n",
      "ARI: 7.346\n",
      "NMI: 36.513\n",
      "Processing i = 4.\n",
      "Iteration number: 65\n",
      "Clustering performance for PV:\n",
      "ARI: 7.160\n",
      "NMI: 32.737\n",
      "Processing i = 5.\n",
      "Iteration number: 62\n",
      "Clustering performance for PV:\n",
      "ARI: 8.124\n",
      "NMI: 37.691\n",
      "Processing i = 6.\n",
      "Iteration number: 27\n",
      "Clustering performance for PV:\n",
      "ARI: 6.234\n",
      "NMI: 31.077\n",
      "Processing i = 7.\n",
      "Iteration number: 91\n",
      "Clustering performance for PV:\n",
      "ARI: 8.127\n",
      "NMI: 36.515\n",
      "Processing i = 8.\n",
      "Iteration number: 121\n",
      "Clustering performance for PV:\n",
      "ARI: 7.286\n",
      "NMI: 33.751\n",
      "Processing i = 9.\n",
      "Iteration number: 85\n",
      "Clustering performance for PV:\n",
      "ARI: 6.593\n",
      "NMI: 32.851\n"
     ]
    }
   ],
   "source": [
    "# For Doc2Vec data need to be tokenized + tagged.\n",
    "tagged_tok_twenty_tot = []\n",
    "\n",
    "for j, sent in enumerate(tok_twenty_tot):\n",
    "    tagged_tok_twenty_tot.append(TaggedDocument(words=sent, tags=[j]))\n",
    "    \n",
    "# Set up d2v model.\n",
    "cores = 6      # Threads used for training\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"Too slow otherwise\"\n",
    "\n",
    "# Initialize 2 models: PV-DBOW and PV-DM.\n",
    "d2v_models = [\n",
    "    # PV-DBOW (dm=0).\n",
    "    Doc2Vec(dm=0, vector_size=n_top_high, window=5, min_count=1, sample=0, workers=cores),\n",
    "    # PV-DM (dm=1) with default averaging.\n",
    "    Doc2Vec(dm=1, vector_size=n_top_high, window=5, min_count=1, sample=0, workers=cores)\n",
    "]\n",
    "\n",
    "# Build the vocabulary\n",
    "for model in d2v_models:\n",
    "    model.build_vocab(tagged_tok_twenty_tot)\n",
    "    print(\"%s vocabulary scanned and state initialized\" % model)\n",
    "    \n",
    "# Train the models.\n",
    "for model in d2v_models: \n",
    "    print(\"Training %s\" % model)\n",
    "    model.train(tagged_tok_twenty_tot, total_examples=model.corpus_count, epochs=30)\n",
    "    \n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for m, model in enumerate(d2v_models):\n",
    "    ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "    NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "    feat_vecs_twenty = [model.infer_vector(doc.words) for doc in tagged_tok_twenty_tot]\n",
    "    for j, ini in enumerate(init_methods):\n",
    "        print(\"Processing init = {}.\".format(ini))\n",
    "        for i in range(10):\n",
    "            print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "            # Initialize the clustering alg.\n",
    "            km_PV = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "            km_PV.fit(feat_vecs_twenty)\n",
    "    \n",
    "            ARI, NMI = evaluate_cluster(km_PV, twenty_labels_tot)\n",
    "    \n",
    "            print(\"Iteration number: {}\".format(km_PV.n_iter_))\n",
    "            print(\"Clustering performance for PV:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "            ARIs[j].append(ARI)\n",
    "            NMIs[j].append(NMI)\n",
    "        \n",
    "    df_cBow = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                           columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "    if m == 0:\n",
    "        df_cBow.round(3).to_csv('results/PV_DBOW_clust_30ep_100topics.csv', header=True, index=False)\n",
    "    else:\n",
    "        df_cBow.round(3).to_csv('results/PV_DM_clust_30ep_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. FV-GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cBow model.\n",
    "w2v_model_twenty = Word2Vec.load(\"models/cBow/cBow_clustering_100topics.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GMM...\n",
      "GMM iteration number: 178.\n",
      "Processing init = random.\n",
      "Processing i = 0.\n",
      "Iteration number: 160\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.777\n",
      "NMI: 3.912\n",
      "Processing i = 1.\n",
      "Iteration number: 183\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.750\n",
      "NMI: 3.873\n",
      "Processing i = 2.\n",
      "Iteration number: 136\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.777\n",
      "NMI: 3.909\n",
      "Processing i = 3.\n",
      "Iteration number: 139\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.777\n",
      "NMI: 3.909\n",
      "Processing i = 4.\n",
      "Iteration number: 200\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.800\n",
      "NMI: 3.831\n",
      "Processing i = 5.\n",
      "Iteration number: 200\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.798\n",
      "NMI: 3.823\n",
      "Processing i = 6.\n",
      "Iteration number: 143\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.782\n",
      "NMI: 3.929\n",
      "Processing i = 7.\n",
      "Iteration number: 152\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.777\n",
      "NMI: 3.909\n",
      "Processing i = 8.\n",
      "Iteration number: 159\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.777\n",
      "NMI: 3.909\n",
      "Processing i = 9.\n",
      "Iteration number: 137\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.779\n",
      "NMI: 3.769\n",
      "Processing init = k-means++.\n",
      "Processing i = 0.\n",
      "Iteration number: 21\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.455\n",
      "NMI: 2.606\n",
      "Processing i = 1.\n",
      "Iteration number: 25\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.455\n",
      "NMI: 2.607\n",
      "Processing i = 2.\n",
      "Iteration number: 36\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.333\n",
      "NMI: 2.496\n",
      "Processing i = 3.\n",
      "Iteration number: 39\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.252\n",
      "NMI: 2.395\n",
      "Processing i = 4.\n",
      "Iteration number: 20\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.308\n",
      "NMI: 2.496\n",
      "Processing i = 5.\n",
      "Iteration number: 26\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.333\n",
      "NMI: 2.522\n",
      "Processing i = 6.\n",
      "Iteration number: 30\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.461\n",
      "NMI: 2.593\n",
      "Processing i = 7.\n",
      "Iteration number: 20\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.453\n",
      "NMI: 2.581\n",
      "Processing i = 8.\n",
      "Iteration number: 23\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.333\n",
      "NMI: 2.519\n",
      "Processing i = 9.\n",
      "Iteration number: 30\n",
      "Clustering performance for FV-GMM:\n",
      "ARI: 0.455\n",
      "NMI: 2.553\n"
     ]
    }
   ],
   "source": [
    "gmm_twenty = mixture.GaussianMixture(n_components=mix_comp, covariance_type='diag', max_iter=200, \n",
    "                                     n_init=5, random_state=22, reg_covar=1e-05)\n",
    "print(\"Fitting GMM...\")\n",
    "\n",
    "gmm_twenty.fit(w2v_model_twenty.wv.vectors)\n",
    "\n",
    "print(\"GMM iteration number: {}.\".format(gmm_twenty.n_iter_))\n",
    "\n",
    "FV_twenty = [FV_GMM(BoWE_doc(w2v_model_twenty.wv, tok_twenty_tot[k]), gmm_twenty) for k in range(len(tok_twenty_tot))]\n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_FV_GMM = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_FV_GMM.fit(FV_twenty)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_FV_GMM, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_FV_GMM.n_iter_))\n",
    "        print(\"Clustering performance for FV-GMM:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_FV_GMM = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                         columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_FV_GMM.round(3).to_csv('results/FV_GMM_clust_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FV_GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. FV-moVMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting moVMF...\n"
     ]
    }
   ],
   "source": [
    "vmf_twenty = VonMisesFisherMixture(n_clusters=mix_comp, posterior_type='soft', max_iter=300, \n",
    "                                   n_init=6, n_jobs=6, copy_x=True, normalize=True, random_state=22)\n",
    "\n",
    "print(\"Fitting moVMF...\")\n",
    "\n",
    "vmf_twenty.fit(normalize(w2v_model_twenty.wv.vectors))\n",
    "\n",
    "FV_twenty = [FV_moVMF(BoWE_doc(w2v_model_twenty.wv, tok_twenty_tot[k]), vmf_twenty) for k in range(len(tok_twenty_tot))]\n",
    "\n",
    "\n",
    "### Try several clustering runs and store results.\n",
    "\n",
    "ARIs = [[], []]    # Store ARI values: random, k-means++ init.\n",
    "NMIs = [[], []]    # Store NMI values: random, k-means++ init.\n",
    "\n",
    "init_methods = ['random', 'k-means++']\n",
    "\n",
    "for j, ini in enumerate(init_methods):\n",
    "    print(\"Processing init = {}.\".format(ini))\n",
    "    for i in range(10):\n",
    "        print(\"Processing i = {}.\".format(i))\n",
    "\n",
    "        # Initialize the clustering alg.\n",
    "        km_FV_moVMF = KMeans(n_clusters=K, n_init=10, init=ini, max_iter=200)\n",
    "        km_FV_moVMF.fit(FV_twenty)\n",
    "    \n",
    "        ARI, NMI = evaluate_cluster(km_FV_moVMF, twenty_labels_tot)\n",
    "    \n",
    "        print(\"Iteration number: {}\".format(km_FV_moVMF.n_iter_))\n",
    "        print(\"Clustering performance for FV-moVMF:\\nARI: {0:.3f}\\nNMI: {1:.3f}\".format(ARI*100, NMI*100))\n",
    "   \n",
    "        ARIs[j].append(ARI)\n",
    "        NMIs[j].append(NMI)\n",
    "        \n",
    "df_FV_moVMF = pd.DataFrame(np.multiply(list(zip(ARIs[0], NMIs[0], ARIs[1], NMIs[1])), 100), \n",
    "                           columns =['ARI_random', 'NMI_random', 'ARI_kmeans', 'NMI_kmeans'])\n",
    "\n",
    "df_FV_moVMF.round(3).to_csv('results/FV_moVMF_clust_100topics.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FV_moVMF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
